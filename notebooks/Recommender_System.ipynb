{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T16:33:26.560999Z",
     "start_time": "2024-04-27T16:33:26.553670Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "pd.set_option('display.max_rows', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3515d828de02a5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import glob\n",
    "\n",
    "base_path = os.path.dirname(os.getcwd())\n",
    "master_data_path = os.path.abspath(os.path.join(base_path,'master-data'))\n",
    "data_path = os.path.abspath(os.path.join(base_path,'data'))\n",
    "images_path = os.path.abspath(os.path.join(base_path,'dm-final-report', 'images'))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "842b57417cc80634",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T16:33:33.855293Z",
     "start_time": "2024-04-27T16:33:33.716626Z"
    }
   },
   "outputs": [],
   "source": [
    "title_basics_crew_principals_ratings_merged_df = pd.read_pickle(os.path.join(data_path,\"title.basics.crew.principals.ratings.cleaned.sav\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca69ec46d8fb907f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "title_principals_df = pd.read_pickle(os.path.join(data_path,\"title.principals.cleaned.sav\"))\n",
    "name_basics_original_df = pd.read_pickle(os.path.join(master_data_path,\"name.basics.sav\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb17794399c97a3",
   "metadata": {},
   "source": [
    "# SOM Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c93f1ca7ba9877d",
   "metadata": {},
   "outputs": [],
   "source": [
    "som_clustered = pd.read_pickle(os.path.join(data_path,\"som_clustered.sav\"))\n",
    "\n",
    "def get_cluster_number(cluster):\n",
    "    return int(cluster.split(\"-\")[0]) * 10 + int(cluster.split(\"-\")[1])\n",
    "\n",
    "som_clustered[\"cluster_number\"] = som_clustered[\"cluster\"].apply(get_cluster_number)\n",
    "som_clustered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b627ffcaf360ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "\n",
    "df = som_clustered\n",
    "df['cluster_number'] = df['cluster_number'].astype(str)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Calculate counts for each 'cluster_number'\n",
    "counts = df['cluster'].value_counts().reset_index()\n",
    "\n",
    "counts.columns = ['cluster', 'count']\n",
    "\n",
    "# Sort the dataframe by 'count' in descending order\n",
    "counts_sorted = counts.sort_values('count', ascending=False)\n",
    "\n",
    "# Create the bar chart\n",
    "fig = px.bar(counts_sorted, x='cluster', y='count', title='Movie Count per Cluster Number')\n",
    "fig.update_layout(\n",
    "    paper_bgcolor='white',  # Set the overall background to white\n",
    "    font_color='black',  # Ensure that the font color is black\n",
    "    title_font_size=20,  # Increase title font size\n",
    "    width=1000,  # Increase figure width\n",
    "    height=800,\n",
    "    font=dict(size=14),  # Increase general font size for axis titles, tick labels, etc.\n",
    "    yaxis=dict(type='log')\n",
    ")\n",
    "fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e507d835050b0f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read_for_kmeans = pd.read_pickle(os.path.join(data_path,\"df_read_for_kmeans.sav\"))\n",
    "df_read_for_kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5edcb7dd08e1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "som_clustered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ca5648ca100078",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for cluster number 19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713e961c29e80fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5943c5f05ee9662f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_number = \"19\"\n",
    "\n",
    "cluster_df = som_clustered[som_clustered[\"cluster_number\"] == cluster_number]\n",
    "\n",
    "merged_df = pd.merge(cluster_df, df_read_for_kmeans, on=\"tconst\", how=\"inner\")\n",
    "\n",
    "df = merged_df.copy()\n",
    "\n",
    "genres_expanded = df['genres'].str.get_dummies(sep=',')\n",
    "df = pd.concat([df, genres_expanded], axis=1).drop('genres', axis=1)\n",
    "\n",
    "# Select numerical columns (excluding 'tconst' which is an identifier)\n",
    "numerical_cols = ['isAdult', 'startYear', 'runtimeMinutes', 'averageRating', 'numVotes',\n",
    "                  'actor_score', 'actress_score', 'director_score', 'writer_score'] + list(genres_expanded.columns)\n",
    "\n",
    "# Normalize these columns\n",
    "scaler = StandardScaler()\n",
    "df[numerical_cols] = scaler.fit_transform(df[numerical_cols])\n",
    "\n",
    "\n",
    "# Compute the cosine similarity matrix\n",
    "cosine_sim_matrix = cosine_similarity(df[numerical_cols])\n",
    "\n",
    "# Convert to DataFrame for better usability, setting the index and columns as movie IDs\n",
    "cosine_sim_df = pd.DataFrame(cosine_sim_matrix, index=df['tconst'], columns=df['tconst'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4341ba8d0327267d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to find most similar movies\n",
    "def get_similar_movies(movie_id, top_n=5):\n",
    "    # Ensure the movie ID is in the index to avoid errors\n",
    "    if movie_id not in cosine_sim_df.index:\n",
    "        return f\"No data available for movie ID {movie_id}\"\n",
    "\n",
    "    # Get the similarity scores for a given movie with all movies\n",
    "    sim_scores = cosine_sim_df.loc[movie_id]\n",
    "\n",
    "    # Sort the movies based on the similarity scores\n",
    "    sim_scores = sim_scores.sort_values(ascending=False)\n",
    "\n",
    "    # Get the scores of the top-n most similar movies\n",
    "    # Skip the first one since it will be the movie itself with a score of 1\n",
    "    top_sim_scores = sim_scores.iloc[1:top_n+1]\n",
    "\n",
    "    # Return the top similar movies and their scores\n",
    "    sim_df = pd.DataFrame({'tconst': top_sim_scores.index, 'Similarity Score': top_sim_scores.values})\n",
    "    similar_movies = pd.merge(sim_df, title_basics_crew_principals_ratings_merged_df, on='tconst', how='inner')[['tconst', 'primaryTitle', 'startYear']]\n",
    "    return similar_movies\n",
    "\n",
    "# Example usage:\n",
    "similar_movies = get_similar_movies('tt0140683')\n",
    "similar_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cacbf744a74f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "def create_cosine_similarity_matrices(som_clustered, df_ready_for_kmeans, clusters):\n",
    "    for cluster in clusters:\n",
    "        print(f\"Creating cosine similarity matrix for cluster {cluster}...\")\n",
    "        cluster_df = som_clustered[som_clustered[\"cluster\"] == cluster]\n",
    "        merged_df = pd.merge(cluster_df, df_ready_for_kmeans, on=\"tconst\", how=\"inner\")\n",
    "        df = merged_df.copy()\n",
    "        \n",
    "        # One-hot encoding genres\n",
    "        genres_expanded = df['genres'].str.get_dummies(sep=',')\n",
    "        df = pd.concat([df, genres_expanded], axis=1).drop('genres', axis=1)\n",
    "        \n",
    "        # Select numerical columns for similarity computation\n",
    "        numerical_cols = ['isAdult', 'startYear', 'runtimeMinutes', 'averageRating', 'numVotes',\n",
    "                          'actor_score', 'actress_score', 'director_score', 'writer_score'] + list(genres_expanded.columns)\n",
    "        \n",
    "        # Normalize these columns\n",
    "        scaler = StandardScaler()\n",
    "        df[numerical_cols] = scaler.fit_transform(df[numerical_cols])\n",
    "        \n",
    "        # Compute the cosine similarity matrix\n",
    "        cosine_sim_matrix = cosine_similarity(df[numerical_cols])\n",
    "        \n",
    "        # Convert to DataFrame for better usability, setting the index and columns as movie IDs\n",
    "        cosine_sim_df = pd.DataFrame(cosine_sim_matrix, index=df['tconst'], columns=df['tconst'])\n",
    "        cosine_sim_df.to_pickle(os.path.join(data_path, \"cosine_sim_data\", f\"cosine_sim_df_cluster_{cluster}.sav\"))\n",
    "        print(f\"Saved cosine similarity matrix for cluster {cluster}.\")\n",
    "\n",
    "\n",
    "def load_all_cosine_sim_dfs(clusters):\n",
    "    all_cosine_sim_dfs = {}\n",
    "    for cluster in clusters:\n",
    "        file_path = os.path.join(data_path, \"cosine_sim_data\", f\"cosine_sim_df_cluster_{cluster}.sav\")\n",
    "        if os.path.exists(file_path):\n",
    "            all_cosine_sim_dfs[cluster] = pd.read_pickle(file_path)\n",
    "            \n",
    "    # dump the pkl\n",
    "    with open(os.path.join(data_path, \"cosine_sim_data\", \"all_cosine_sim_dfs.pkl\"), \"wb\") as f:\n",
    "        pickle.dump(all_cosine_sim_dfs, f)\n",
    "        \n",
    "    # read the pkl\n",
    "    with open(os.path.join(data_path, \"cosine_sim_data\", \"all_cosine_sim_dfs.pkl\"), \"rb\") as f:\n",
    "        all_cosine_sim_dfs = pickle.load(f)\n",
    "    return all_cosine_sim_dfs\n",
    "\n",
    "def find_similar_movies(tconst,som_clustered, all_cosine_sim_dfs):\n",
    "    # Determine the cluster of the movie\n",
    "    if tconst in som_clustered['tconst'].values:\n",
    "        cluster = som_clustered.loc[som_clustered['tconst'] == tconst, 'cluster'].iloc[0]\n",
    "        cosine_sim_df = all_cosine_sim_dfs[cluster]\n",
    "        \n",
    "        # Get the top 5 similar movies\n",
    "        sim_scores = cosine_sim_df.loc[tconst].sort_values(ascending=False)[1:6]\n",
    "        title_basics_crew_principals_ratings_merged_df = pd.read_pickle(os.path.join(data_path,\"title.basics.crew.principals.ratings.cleaned.sav\"))\n",
    "        similar_movies = title_basics_crew_principals_ratings_merged_df[title_basics_crew_principals_ratings_merged_df['tconst'].isin(sim_scores.index)]\n",
    "        similar_movies = similar_movies.assign(Similarity=sim_scores.values)\n",
    "        return similar_movies[['tconst', 'primaryTitle', 'startYear', 'Similarity']]\n",
    "    else:\n",
    "        return \"Movie ID not found.\"\n",
    "\n",
    "# Example usage\n",
    "som_clustered = pd.read_pickle(os.path.join(data_path,\"som_clustered.sav\"))\n",
    "df_ready_for_kmeans = pd.read_pickle(os.path.join(data_path,\"df_read_for_kmeans.sav\"))\n",
    "\n",
    "clusters = som_clustered['cluster'].unique()\n",
    "\n",
    "# create_cosine_similarity_matrices(som_clustered, df_ready_for_kmeans, clusters)\n",
    "all_cosine_sim_dfs = load_all_cosine_sim_dfs(clusters)\n",
    "similar_movies = find_similar_movies('tt1375666', som_clustered, all_cosine_sim_dfs)\n",
    "similar_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10add0da4da4bd48",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T16:33:39.891433Z",
     "start_time": "2024-04-27T16:33:39.712594Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tconst</th>\n",
       "      <th>primaryTitle</th>\n",
       "      <th>startYear</th>\n",
       "      <th>cluster</th>\n",
       "      <th>averageRating</th>\n",
       "      <th>numVotes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45617</th>\n",
       "      <td>tt1375666</td>\n",
       "      <td>Inception</td>\n",
       "      <td>2010</td>\n",
       "      <td>0-6</td>\n",
       "      <td>8.8</td>\n",
       "      <td>2537886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38365</th>\n",
       "      <td>tt0816692</td>\n",
       "      <td>Interstellar</td>\n",
       "      <td>2014</td>\n",
       "      <td>2-9</td>\n",
       "      <td>8.7</td>\n",
       "      <td>2082145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55317</th>\n",
       "      <td>tt0133093</td>\n",
       "      <td>The Matrix</td>\n",
       "      <td>1999</td>\n",
       "      <td>0-6</td>\n",
       "      <td>8.7</td>\n",
       "      <td>2042794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32782</th>\n",
       "      <td>tt0167260</td>\n",
       "      <td>The Lord of the Rings: The Return of the King</td>\n",
       "      <td>2003</td>\n",
       "      <td>2-9</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1969825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>tt0114369</td>\n",
       "      <td>Se7en</td>\n",
       "      <td>1995</td>\n",
       "      <td>3-9</td>\n",
       "      <td>8.6</td>\n",
       "      <td>1789345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94542</th>\n",
       "      <td>tt0100110</td>\n",
       "      <td>Le marché du couple</td>\n",
       "      <td>1990</td>\n",
       "      <td>9-9</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56739</th>\n",
       "      <td>tt2437612</td>\n",
       "      <td>The Hobby Stop</td>\n",
       "      <td>2012</td>\n",
       "      <td>5-5</td>\n",
       "      <td>8.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>659</th>\n",
       "      <td>tt15510976</td>\n",
       "      <td>A Filha Do Governador 2</td>\n",
       "      <td>2016</td>\n",
       "      <td>9-3</td>\n",
       "      <td>9.6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52732</th>\n",
       "      <td>tt8391544</td>\n",
       "      <td>Ticket</td>\n",
       "      <td>2019</td>\n",
       "      <td>6-6</td>\n",
       "      <td>6.6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89276</th>\n",
       "      <td>tt6522396</td>\n",
       "      <td>Shoals</td>\n",
       "      <td>2011</td>\n",
       "      <td>3-9</td>\n",
       "      <td>8.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           tconst                                   primaryTitle  startYear  \\\n",
       "45617   tt1375666                                      Inception       2010   \n",
       "38365   tt0816692                                   Interstellar       2014   \n",
       "55317   tt0133093                                     The Matrix       1999   \n",
       "32782   tt0167260  The Lord of the Rings: The Return of the King       2003   \n",
       "15      tt0114369                                          Se7en       1995   \n",
       "...           ...                                            ...        ...   \n",
       "94542   tt0100110                            Le marché du couple       1990   \n",
       "56739   tt2437612                                 The Hobby Stop       2012   \n",
       "659    tt15510976                        A Filha Do Governador 2       2016   \n",
       "52732   tt8391544                                         Ticket       2019   \n",
       "89276   tt6522396                                         Shoals       2011   \n",
       "\n",
       "      cluster  averageRating  numVotes  \n",
       "45617     0-6            8.8   2537886  \n",
       "38365     2-9            8.7   2082145  \n",
       "55317     0-6            8.7   2042794  \n",
       "32782     2-9            9.0   1969825  \n",
       "15        3-9            8.6   1789345  \n",
       "...       ...            ...       ...  \n",
       "94542     9-9            6.0         5  \n",
       "56739     5-5            8.8         5  \n",
       "659       9-3            9.6         5  \n",
       "52732     6-6            6.6         5  \n",
       "89276     3-9            8.4         5  \n",
       "\n",
       "[100000 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "som_clustered.merge(title_basics_crew_principals_ratings_merged_df, on=\"tconst\", how=\"inner\")[['tconst', 'primaryTitle', 'startYear', 'cluster', 'averageRating', 'numVotes']].sort_values(by=\"numVotes\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "487ed25e283a91d4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T16:38:18.000500Z",
     "start_time": "2024-04-27T16:38:17.065157Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llrr}\n",
      "\\toprule\n",
      "tconst & primaryTitle & startYear & Similarity \\\\\n",
      "\\midrule\n",
      "tt0375679 & Crash & 2004 & 0.978776 \\\\\n",
      "tt0407887 & The Departed & 2006 & 0.975251 \\\\\n",
      "tt0477348 & No Country for Old Men & 2007 & 0.920194 \\\\\n",
      "tt0765443 & Eastern Promises & 2007 & 0.917364 \\\\\n",
      "tt7286456 & Joker & 2019 & 0.887485 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "base_path = os.path.dirname(os.getcwd())\n",
    "data_path = os.path.abspath(os.path.join(base_path,'data'))\n",
    "\n",
    "\n",
    "som_clustered = pd.read_pickle(os.path.join(data_path,\"som_clustered.sav\"))\n",
    "df_ready_for_kmeans = pd.read_pickle(os.path.join(data_path,\"df_read_for_kmeans.sav\"))\n",
    "\n",
    "clusters = som_clustered['cluster'].unique()\n",
    "\n",
    "\n",
    "def load_all_cosine_sim_dfs():\n",
    "    with open(os.path.join(data_path, \"cosine_sim_data\", \"all_cosine_sim_dfs.pkl\"), \"rb\") as f:\n",
    "        all_cosine_sim_dfs = pickle.load(f)\n",
    "        \n",
    "    return all_cosine_sim_dfs\n",
    "\n",
    "def find_similar_movies(tconst,som_clustered, all_cosine_sim_dfs):\n",
    "    # Determine the cluster of the movie\n",
    "    if tconst in som_clustered['tconst'].values:\n",
    "        cluster = som_clustered.loc[som_clustered['tconst'] == tconst, 'cluster'].iloc[0]\n",
    "        cosine_sim_df = all_cosine_sim_dfs[cluster]\n",
    "        \n",
    "        # Get the top 5 similar movies\n",
    "        sim_scores = cosine_sim_df.loc[tconst].sort_values(ascending=False)[1:6]\n",
    "        title_basics_crew_principals_ratings_merged_df = pd.read_pickle(os.path.join(data_path,\"title.basics.crew.principals.ratings.cleaned.sav\"))\n",
    "        similar_movies = title_basics_crew_principals_ratings_merged_df[title_basics_crew_principals_ratings_merged_df['tconst'].isin(sim_scores.index)]\n",
    "        similar_movies = similar_movies.assign(Similarity=sim_scores.values)\n",
    "        return similar_movies[['tconst', 'primaryTitle', 'startYear', 'Similarity']].reset_index(drop=True)\n",
    "    else:\n",
    "        return \"Movie ID not found.\"\n",
    "\n",
    "all_cosine_sim_dfs = load_all_cosine_sim_dfs()\n",
    "similar_movies = find_similar_movies('tt0102926', som_clustered, all_cosine_sim_dfs)\n",
    "print(similar_movies.to_latex(index=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
